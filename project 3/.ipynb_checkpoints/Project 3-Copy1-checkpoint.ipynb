{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create timestamp for posts\n",
    "d_end = datetime.date(2019,7,17)\n",
    "unixtime_end = int(time.mktime(d_end.timetuple()))\n",
    "d_start = datetime.date(2018,7,17)\n",
    "unixtime_start = int(time.mktime(d_start.timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_url = \"https://api.pushshift.io/reddit/search/submission/?subreddit=singapore&sort=desc&sort_type=created_utc&after={}&before={}&size=1000\" .format(unixtime_start,unixtime_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_url = \"https://api.pushshift.io/reddit/search/submission/?subreddit=japan&sort=desc&sort_type=created_utc&after={}&before={}&size=1000\" .format(unixtime_start,unixtime_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class url_prep:\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url   \n",
    "    \n",
    "    def request (self):\n",
    "        headers ={\"user-agent\" :\"Bleep blorp bot 0.2\"}\n",
    "        url_res = requests.get(self.url, headers=headers)\n",
    "        self.json = url_res.json()\n",
    "        self.key = sorted(url_res.json().keys())\n",
    "        self.len = len(self.json[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = url_prep(sg_url)\n",
    "jp = url_prep(jp_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n",
      "1000\n",
      "['data']\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "countries = [sg,jp]\n",
    "for country in countries:\n",
    "    country.request()\n",
    "    print(country.key)\n",
    "    print(country.len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all_awardings', 'allow_live_comments', 'author', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_patreon_flair', 'can_mod_post', 'contest_mode', 'created_utc', 'domain', 'full_link', 'gildings', 'id', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video', 'link_flair_background_color', 'link_flair_richtext', 'link_flair_text_color', 'link_flair_type', 'locked', 'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'pwls', 'retrieved_on', 'score', 'selftext', 'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers', 'subreddit_type', 'thumbnail', 'title', 'total_awards_received', 'updated_utc', 'url', 'whitelist_status', 'wls'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg.json[\"data\"][0].keys() #to find out dict keys within data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return \"Non English\"\n",
    "    else:\n",
    "        return \"English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    country.title_data =[]\n",
    "    country.subreddit_data = []\n",
    "    country.type_data = []\n",
    "    for i in range(country.len):\n",
    "        title =  country.json[\"data\"][i][\"title\"]\n",
    "        country.title_data.append (title)\n",
    "        subreddit =  country.json[\"data\"][i][\"subreddit\"]\n",
    "        country.subreddit_data.append (subreddit)\n",
    "        word = isEnglish(country.json[\"data\"][i][\"title\"])\n",
    "        country.type_data.append (word)\n",
    "        country.data_posts = pd.DataFrame(country.title_data, columns=[\"title\"])\n",
    "        country.data_posts = country.data_posts.join (pd.DataFrame(country.subreddit_data, columns=[\"subreddit\"]))\n",
    "        country.data_posts = country.data_posts.join (pd.DataFrame(country.type_data, columns=[\"type\"]))\n",
    "        country.data_posts = country.data_posts[country.data_posts.type != 'Non English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 3)\n",
      "(923, 3)\n"
     ]
    }
   ],
   "source": [
    "print (jp.data_posts.shape)\n",
    "print (sg.data_posts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [jp.data_posts, sg.data_posts]\n",
    "data_finalposts = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This coin laundry in Tokyo really doesn't want...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pedestrians walk on bustling Dotombori Street ...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking for \"mouko tanmen nakamoto spicy ramen...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 days in Tokyo, leave suggestions below please!!</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glen Wood: \"Paternity Harassment: Glen Wood vs...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>School issues are No. 1 reason behind youth su...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japan's defense chief has 'no plan' to dispatc...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Talent at Japan's Biggest Agency to Pledge Not...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>An American baseball player of Fukuoka Softban...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hello fellow Japanese redditors, I'm lookin fo...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Anyone able to translate this T-shirt for me.</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>is there intolerance towards black people in j...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>US State Department Highlights Japan Human Rig...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Finding a FISH GRILL like the one in Japanese ...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Japan Sees No Talks Soon on Its Export Curbs t...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Planning a honeymoon trip to Japan on January ...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How a small dairy store from Ohio became one o...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Koreans' view of Japan falls to record low: poll</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Why did a random ass Japanese girl wave at me?...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Which proxy service will do in-store shopping ...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What is this religious ceremony that took plac...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I spent 20 days in Japanese detention - AMA?</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I will be headed to Japan in a month!</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A park in matsudo.</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I am trying to get this in the United States. ...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Will christianity in japan</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Should Japan require travel visas?</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Does anyone have experience filing a police re...</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Why emperor meiji</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Can royaltys of japan become samurais</td>\n",
       "      <td>japan</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Waiting for Sunrise.</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>9 in 10 PMD users believe they are considerate...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Thoughts on Single Joint-account for newly weds</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Perfect high kneel form. Sign on sua.</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Best Ride Share Driver Ever? | FIVE TO NINE</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>Jewel vs Science Centre...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Looking for opinions</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Best places to play basketball in Singapore?</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>Travelling to Singapore with drone</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>Where in Singapore can I get Microsoft Office ...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>SPF Enlistment 9 July 2019</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>A Singaporean JJBA Cosplayer , circa 4-09-2002...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>What are some unique/niche malls in Singapore ...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Questions about wildlife in Singapore; Part 35...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>eae shortlist notification</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Ouch mayn</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Masjid Sultan</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>He Gives The Disabled Work And Dignity In This...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Singapore has clear waters (Labrador Park)</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Scammers posing as Singapore CID asking for AT...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Review of transport fare formula needed to ref...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>ITE graduate takes the road less travelled to ...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Hi r/singapore. What do you guys love &amp;amp; ha...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>H2 Computing. Send halp ples.</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Full-time Grab drivers, how are your earnings?...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Mandatory registration for drones by year-end ...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Parliament: Traffic Police plan to stop issuin...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Singaporean driver fined $2,600 for switching ...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Do you want to have kids in Singapore? Why or ...</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Singapore has clear waters (Labrador Park)</td>\n",
       "      <td>singapore</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  subreddit     type\n",
       "0    This coin laundry in Tokyo really doesn't want...      japan  English\n",
       "1    Pedestrians walk on bustling Dotombori Street ...      japan  English\n",
       "2    looking for \"mouko tanmen nakamoto spicy ramen...      japan  English\n",
       "3    5 days in Tokyo, leave suggestions below please!!      japan  English\n",
       "4    Glen Wood: \"Paternity Harassment: Glen Wood vs...      japan  English\n",
       "5    School issues are No. 1 reason behind youth su...      japan  English\n",
       "6    Japan's defense chief has 'no plan' to dispatc...      japan  English\n",
       "8    Talent at Japan's Biggest Agency to Pledge Not...      japan  English\n",
       "9    An American baseball player of Fukuoka Softban...      japan  English\n",
       "10   Hello fellow Japanese redditors, I'm lookin fo...      japan  English\n",
       "11       Anyone able to translate this T-shirt for me.      japan  English\n",
       "12   is there intolerance towards black people in j...      japan  English\n",
       "13   US State Department Highlights Japan Human Rig...      japan  English\n",
       "14   Finding a FISH GRILL like the one in Japanese ...      japan  English\n",
       "15   Japan Sees No Talks Soon on Its Export Curbs t...      japan  English\n",
       "17   Planning a honeymoon trip to Japan on January ...      japan  English\n",
       "18   How a small dairy store from Ohio became one o...      japan  English\n",
       "19    Koreans' view of Japan falls to record low: poll      japan  English\n",
       "20   Why did a random ass Japanese girl wave at me?...      japan  English\n",
       "21   Which proxy service will do in-store shopping ...      japan  English\n",
       "23   What is this religious ceremony that took plac...      japan  English\n",
       "24        I spent 20 days in Japanese detention - AMA?      japan  English\n",
       "26               I will be headed to Japan in a month!      japan  English\n",
       "27                                  A park in matsudo.      japan  English\n",
       "28   I am trying to get this in the United States. ...      japan  English\n",
       "29                          Will christianity in japan      japan  English\n",
       "30                  Should Japan require travel visas?      japan  English\n",
       "31   Does anyone have experience filing a police re...      japan  English\n",
       "32                                   Why emperor meiji      japan  English\n",
       "33               Can royaltys of japan become samurais      japan  English\n",
       "..                                                 ...        ...      ...\n",
       "969                               Waiting for Sunrise.  singapore  English\n",
       "970  9 in 10 PMD users believe they are considerate...  singapore  English\n",
       "971    Thoughts on Single Joint-account for newly weds  singapore  English\n",
       "972              Perfect high kneel form. Sign on sua.  singapore  English\n",
       "973        Best Ride Share Driver Ever? | FIVE TO NINE  singapore  English\n",
       "974                         Jewel vs Science Centre...  singapore  English\n",
       "975                               Looking for opinions  singapore  English\n",
       "976       Best places to play basketball in Singapore?  singapore  English\n",
       "977                 Travelling to Singapore with drone  singapore  English\n",
       "978  Where in Singapore can I get Microsoft Office ...  singapore  English\n",
       "979                         SPF Enlistment 9 July 2019  singapore  English\n",
       "980  A Singaporean JJBA Cosplayer , circa 4-09-2002...  singapore  English\n",
       "981  What are some unique/niche malls in Singapore ...  singapore  English\n",
       "982  Questions about wildlife in Singapore; Part 35...  singapore  English\n",
       "983                         eae shortlist notification  singapore  English\n",
       "984                                          Ouch mayn  singapore  English\n",
       "985                                      Masjid Sultan  singapore  English\n",
       "986  He Gives The Disabled Work And Dignity In This...  singapore  English\n",
       "987         Singapore has clear waters (Labrador Park)  singapore  English\n",
       "988  Scammers posing as Singapore CID asking for AT...  singapore  English\n",
       "989  Review of transport fare formula needed to ref...  singapore  English\n",
       "990  ITE graduate takes the road less travelled to ...  singapore  English\n",
       "991  Hi r/singapore. What do you guys love &amp; ha...  singapore  English\n",
       "992                      H2 Computing. Send halp ples.  singapore  English\n",
       "993  Full-time Grab drivers, how are your earnings?...  singapore  English\n",
       "995  Mandatory registration for drones by year-end ...  singapore  English\n",
       "996  Parliament: Traffic Police plan to stop issuin...  singapore  English\n",
       "997  Singaporean driver fined $2,600 for switching ...  singapore  English\n",
       "998  Do you want to have kids in Singapore? Why or ...  singapore  English\n",
       "999         Singapore has clear waters (Labrador Park)  singapore  English\n",
       "\n",
       "[1819 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_finalposts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_finalposts.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineer a feature to turn `subreddit types` into a 1/0 column, where 1 indicates `Japan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_finalposts[\"source\"] = [1 if data_finalposts['subreddit'][i]==\"japan\" else 0 for i in range(len(data_finalposts.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_finalposts.title\n",
    "y = data_finalposts.source.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_evaluation:\n",
    "   \n",
    "    def __init__(self, y_test, predicted_value):\n",
    "        self.y_test = y_test\n",
    "        self.predicted_value = predicted_value\n",
    "        \n",
    "    def confusion_matrix (self):\n",
    "        tn, fp, fn, tp = confusion_matrix(self.y_test, self.predicted_value).ravel()\n",
    "        print(\"True Negatives: %s\" % tn)\n",
    "        print(\"False Positives: %s\" % fp)\n",
    "        print(\"False Negatives: %s\" % fn)\n",
    "        print(\"True Positives: %s\" % tp)\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        print(\"Precision: {}\" .format (tp/(tp+fp)))\n",
    "        print(\"Recall: {}\" .format (tp/(tp+fn)))\n",
    "        F1_score = 2*((precision*recall)/(precision+recall))\n",
    "        print (\"F1 score: {}\" .format(2*((precision*recall)/(precision+recall))))\n",
    "        self.score = F1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opt 1: Evaluate the performance of a Logistic Regression on the features extracted by the CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtext_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('lr', LogisticRegression())])\n",
    "lrtuned_parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)], #The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n <= n <= max_n will be used\n",
    "    'lr__solver': [\"lbfgs\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 204\n",
      "False Positives: 27\n",
      "False Negatives: 61\n",
      "True Positives: 163\n",
      "Precision: 0.8578947368421053\n",
      "Recall: 0.7276785714285714\n",
      "F1 score: 0.78743961352657\n"
     ]
    }
   ],
   "source": [
    "lr = GridSearchCV(lrtext_clf, lrtuned_parameters, cv=10)\n",
    "lr.fit(X_train, y_train)\n",
    "predicted_lr = lr.predict(X_test)\n",
    "lrg = model_evaluation (y_test,predicted_lr)\n",
    "lrg.confusion_matrix ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opt 2: Fit a Multinomial Naive Bayes model wtih cvec!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "tuned_parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)], #The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n <= n <= max_n will be used\n",
    "    'clf__alpha': [1, 1e-1, 1e-2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 182\n",
      "False Positives: 49\n",
      "False Negatives: 34\n",
      "True Positives: 190\n",
      "Precision: 0.7949790794979079\n",
      "Recall: 0.8482142857142857\n",
      "F1 score: 0.8207343412526998\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=10)\n",
    "clf.fit(X_train, y_train)\n",
    "predicted_nbcvec = clf.predict(X_test)\n",
    "nbcvec = model_evaluation (y_test,predicted_nbcvec)\n",
    "nbcvec.confusion_matrix ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opt 3: Fit a Multinomial Naive Bayes model with Tfid!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tclf = Pipeline([('Tvect', TfidfVectorizer()),\n",
    "                     ('tclf', MultinomialNB())])\n",
    "tuned_tparameters = {\n",
    "    'Tvect__ngram_range': [(1, 1), (1, 2), (2, 2)], #The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n <= n <= max_n will be used\n",
    "    'tclf__alpha': [1, 1e-1, 1e-2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 186\n",
      "False Positives: 45\n",
      "False Negatives: 37\n",
      "True Positives: 187\n",
      "Precision: 0.8060344827586207\n",
      "Recall: 0.8348214285714286\n",
      "F1 score: 0.8201754385964911\n"
     ]
    }
   ],
   "source": [
    "tclf = GridSearchCV(text_tclf, tuned_tparameters, cv=10)\n",
    "tclf.fit(X_train, y_train)\n",
    "predicted_nbtvec = tclf.predict(X_test)\n",
    "nbtvec = model_evaluation (y_test,predicted_nbtvec)\n",
    "nbtvec.confusion_matrix ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score - Logistic regression with cvec 0.78743961352657\n",
      "F1 score - Multinomial Naive Bayes model wtih cvec 0.8207343412526998\n",
      "F1 score - Multinomial Naive Bayes model with Tfid  0.8201754385964911\n"
     ]
    }
   ],
   "source": [
    "print (\"F1 score - Logistic regression with cvec {}\" .format(lrg.score))\n",
    "print (\"F1 score - Multinomial Naive Bayes model wtih cvec {}\" .format(nbcvec.score))\n",
    "print (\"F1 score - Multinomial Naive Bayes model with Tfid  {}\" .format(nbtvec.score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
